# Binary
Binary code is the fundamental language of the computer, using only two digits (**0s** and **1s**) to represent data in a computer system.

## Bits and bytes
Each zero or one is called a **bit** (binary digit), which is held in [[storage/home]] using some form of on/off switch. You can use a form of binary counting to count to 31 on the fingers of one hand.

If your thumb is worth 1, each finger doubles in value: your index finger is worth 2, middle finger is 4, ring finger is 8 and little finger is 16:
![[hand.png]]

Using this system, we can count from zero (closed fist) to 31 (all fingers outstretched), and each number in-between:

![[binary counting on fingers.png]]


The way that bits are represented is different in [[magnetic]], [[optical]] and [[solid state]] storage devices, but the principle remains the same: combinations of 0s and 1s just like the fingers 
Bits can be combined into **strings** that can represent a wide variety of different kinds of data, including:

#### Text
Each letter of the alphabet is **one byte long**, with each letter being represented in binary by eight bits, as follows:

| Letter | Binary   |
|--------|----------|
| A      | 01000001 |
| B      | 01000010 |
| C      | 01000011 |
| D      | 01000100 |

